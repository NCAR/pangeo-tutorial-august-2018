{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.6. Dask Array\n",
    "\n",
    "![](dask-array-black-text.svg)\n",
    "\n",
    "*From the Dask documentation:*\n",
    "> Dask Array implements a subset of the NumPy ndarray interface using \n",
    "> blocked algorithms, cutting up the large array into many small arrays. \n",
    "> This lets us compute on arrays larger than memory using all of our cores. \n",
    "> We coordinate these blocked algorithms using dask graphs.\n",
    "\n",
    "Dask Arrays provide \"a parallel, larger-than-memory, n-dimensional array using blocked algorithms. Simply put: distributed Numpy.\n",
    "\n",
    "- **Parallel:** Uses all of the cores on your computer\n",
    "- **Larger-than-memory:** Lets you work on datasets that are larger than your available memory by breaking up your array into many small pieces, operating on those pieces in an order that minimizes the memory footprint of your computation, and effectively streaming data from disk.\n",
    "- **Blocked Algorithms:** Perform large computations by performing many smaller computations\"\n",
    "\n",
    "*Stolen from the Dask tutorial: https://github.com/dask/dask-tutorial*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import LocalCluster, Client\n",
    "\n",
    "cluster = LocalCluster(n_workers=4)\n",
    "\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.array as da\n",
    "import netCDF4 as nc4\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dask Arrays from Numpy Arrays\n",
    "\n",
    "One of the easiest ways of creating Dask Arrays is directly from Numpy arrays using the `from_array` function of `dask.array`.  This function accepts anything that is \"array-like,\" such as:\n",
    "\n",
    "- a netCDF4 variable from netCDF4-python,\n",
    "- an HDF5 field using h5py,\n",
    "- a Numpy array,\n",
    "\n",
    "or any other object that can be indexed like a Numpy array.\n",
    "\n",
    "It takes the \"array-like\" object and a tuple for the `chunks` parameter, which specifies the size of each chunk of the array along each array axis.\n",
    "\n",
    "In this example, we'll create a distributed Dask Array from NetCDF file...but first we have to create some NetCDF data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_SIZE = 2560\n",
    "\n",
    "for n in range(4):\n",
    "    i, j = divmod(n, 2)\n",
    "    ncds = nc4.Dataset('./data/data-{}x{}.nc'.format(i, j), 'w')\n",
    "    ncds.createDimension('x', DIM_SIZE)\n",
    "    ncds.createDimension('y', DIM_SIZE)\n",
    "    x = ncds.createVariable('x', 'd', ('x',))\n",
    "    y = ncds.createVariable('y', 'd', ('y',))\n",
    "    v = ncds.createVariable('v', 'f', ('x', 'y'))\n",
    "    u = ncds.createVariable('u', 'f', ('x', 'y'))\n",
    "    x[:] = np.arange(i*DIM_SIZE, (i+1)*DIM_SIZE)\n",
    "    y[:] = np.arange(j*DIM_SIZE, (j+1)*DIM_SIZE)\n",
    "    v[:] = np.random.random((DIM_SIZE, DIM_SIZE)).astype('f')\n",
    "    u[:] = np.random.random((DIM_SIZE, DIM_SIZE)).astype('f')\n",
    "    ncds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -lh data*.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncds = nc4.Dataset('./data/data-0x0.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v00 = da.from_array(ncds.variables['v'], chunks=(1280, 1280))\n",
    "v00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, take a look at the Dashboard, again.**  Look at the *Bytes stored* section of the Dashboard Status page. \n",
    "\n",
    "The creation of the Dask Array is a lazy operation, and the data isn't read from disk until you actually call compute!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v00.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v00.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v00.numblocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that slicing is *also* a lazy operation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v00_5x5 = v00[:5, :5]\n",
    "v00_5x5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's only when we `compute` the result that data is read from disk..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v00_5x5.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take a look at the *Bytes stored* section of the Dashboard Status page, again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dask Arrays from Delayed Objects\n",
    "\n",
    "In addition to reading array-like objects as Dasy Arrays, you can construct an array from `Delayed` objects, giving you a little more flexibility in what you can construct an array from.\n",
    "\n",
    "### Using Delayed to Lazily Read Multiple Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readvar(fname, vname):\n",
    "    ds = nc4.Dataset(fname)\n",
    "    varray = dask.delayed(ds.variables[vname])[:]\n",
    "    vshape = ds.variables[vname].shape\n",
    "    vdtype = ds.variables[vname].dtype\n",
    "    return varray, vshape, vdtype, '{}-{}'.format(vname, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varrays = [da.from_delayed(*readvar(fname, 'v')) for fname in glob.glob('./data/data-*.nc')]\n",
    "uarrays = [da.from_delayed(*readvar(fname, 'u')) for fname in glob.glob('./data/data-*.nc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varrays[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([v.name for v in varrays])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varrays[0].visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = da.concatenate([da.concatenate(varrays[:2], axis=1), da.concatenate(varrays[2:], axis=1)])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = da.concatenate([da.concatenate(uarrays[:2], axis=1), da.concatenate(uarrays[2:], axis=1)])\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.numblocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical Operations\n",
    "\n",
    "Most of the Numpy API is mirrored in Dask Array.\n",
    "\n",
    "### Example: Sum\n",
    "So, you can do operations like sum over an axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_v = v.sum(axis=1)\n",
    "sum_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_v.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_v.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Matrix Multiplation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_x_u = v @ u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_x_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_x_u.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_x_u = v_x_u.persist()\n",
    "v_x_u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rechunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_2 = v.rechunk((1280,1280)).persist()\n",
    "u_2 = v.rechunk((1280,1280)).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_2.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_x_u_2 = v_2 @ u_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_x_u_2.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So much easier with Xarray..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -lh data-*.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ds = []\n",
    "for i in range(2):\n",
    "    _ds.append(xr.open_mfdataset(glob.glob('./data/data-{}*.nc'.format(i)), chunks={'x': 1280, 'y': 1280}, concat_dim='y'))\n",
    "ds = xr.concat(_ds, dim='x')\n",
    "\n",
    "ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
